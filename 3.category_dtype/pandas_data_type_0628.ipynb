{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (lighter | faster | safer | flexible | fool-proof)\n",
    "\n",
    "# How to Encode Categorical data: Unleash the power of 'category' dtypes\n",
    "\n",
    "### hands-on tutorials of using 'category' data type in Python\n",
    "\n",
    "Lately, I was worknig on a former Kaggle competition dataset- Talking data, predict customer demographics. The original dataset includes 8 data frames, in which 5 of them I think is relevant; all in 'csv' format, total size 2G. But after I tried to merge the data frames into a single tabular data frame. BOOM, 2G explode to 18G. ðŸ˜Ÿ\n",
    "\n",
    "Luckily there are easy fixes. After some simple tricks, I was able to make the dataset from 18G to 5G, without losing any information or change of the data structure.  The way I do it is by using 'category' date type. \n",
    "\n",
    "Later, I found out 'category' data type not only can make the dataset light-weighted, but also help to improve data operation performance and machine learning performance.\n",
    "\n",
    "So, today I will talk about how to use 'category' dtype in Python and why you should consider use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to cover\n",
    "\n",
    "- [ ]  show starter: lighter and faster\n",
    "- [ ]  explain how 'category' dtypes works\n",
    "- [ ]  why it matters to machine learning\n",
    "- [ ]  takeaways: when you should use 'category'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this article for you?\n",
    "\n",
    "The goal of this tutorial is not to cover up the very rich top of categorical encoding. (I doubt anybody can do that in just one blog.) Instead, the focus is on Python and its Pandas library. But if you are not a Python user or work closely with Pandas, don't worry. I believe this post can still shed some light.\n",
    "\n",
    "Like always, I will explain in a hands-on style. Without further ado, let's make our hands dirty and jump into the dataset. Here is the link you can download the example data (We will not work on the whole dataset, but a portion of it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>app_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>brand_parse</th>\n",
       "      <th>model_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2466991</td>\n",
       "      <td>2016-05-01 00:43:07</td>\n",
       "      <td>117.09</td>\n",
       "      <td>36.12</td>\n",
       "      <td>8165649363453695304</td>\n",
       "      <td>1438711534922792517</td>\n",
       "      <td>713</td>\n",
       "      <td>M</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>A33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370002</td>\n",
       "      <td>2016-05-04 08:11:03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-755461362045697404</td>\n",
       "      <td>-2449610688324901118</td>\n",
       "      <td>548</td>\n",
       "      <td>F</td>\n",
       "      <td>Meizu</td>\n",
       "      <td>Charm Blue NOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1608644</td>\n",
       "      <td>2016-05-02 13:56:37</td>\n",
       "      <td>116.28</td>\n",
       "      <td>40.10</td>\n",
       "      <td>8893877044209647765</td>\n",
       "      <td>4075941473982616348</td>\n",
       "      <td>206</td>\n",
       "      <td>F</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Glory 6 Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3008180</td>\n",
       "      <td>2016-05-03 19:02:56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1633887856876571208</td>\n",
       "      <td>1915112695298339924</td>\n",
       "      <td>779</td>\n",
       "      <td>F</td>\n",
       "      <td>OPPO</td>\n",
       "      <td>R7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107379</td>\n",
       "      <td>2016-05-02 17:44:32</td>\n",
       "      <td>116.50</td>\n",
       "      <td>39.91</td>\n",
       "      <td>2229153468836897886</td>\n",
       "      <td>7353572136329657630</td>\n",
       "      <td>782</td>\n",
       "      <td>F</td>\n",
       "      <td>Huawei</td>\n",
       "      <td>Mate 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            timestamp  longitude  latitude               app_id  \\\n",
       "0   2466991  2016-05-01 00:43:07     117.09     36.12  8165649363453695304   \n",
       "1    370002  2016-05-04 08:11:03       0.00      0.00  -755461362045697404   \n",
       "2   1608644  2016-05-02 13:56:37     116.28     40.10  8893877044209647765   \n",
       "3   3008180  2016-05-03 19:02:56       0.00      0.00 -1633887856876571208   \n",
       "4    107379  2016-05-02 17:44:32     116.50     39.91  2229153468836897886   \n",
       "\n",
       "             device_id  label_id gender brand_parse      model_parse  \n",
       "0  1438711534922792517       713      M        OPPO              A33  \n",
       "1 -2449610688324901118       548      F       Meizu  Charm Blue NOTE  \n",
       "2  4075941473982616348       206      F      Huawei     Glory 6 Plus  \n",
       "3  1915112695298339924       779      F        OPPO              R7s  \n",
       "4  7353572136329657630       782      F      Huawei           Mate 7  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/kefeimo/DataScienceBlog/master/3.category_dtype/df_example.csv'\n",
    "df_original = pd.read_csv(url)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   event_id     130821 non-null  int64  \n",
      " 1   timestamp    130821 non-null  object \n",
      " 2   longitude    130821 non-null  float64\n",
      " 3   latitude     130821 non-null  float64\n",
      " 4   app_id       130821 non-null  int64  \n",
      " 5   device_id    130821 non-null  int64  \n",
      " 6   label_id     130821 non-null  int64  \n",
      " 7   gender       130821 non-null  object \n",
      " 8   brand_parse  130821 non-null  object \n",
      " 9   model_parse  130821 non-null  object \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the dataframe info, there are 130,821 rows, 10 columns (2+4+4) and the number of float, int, object variables are 2, 4, 4, respectively.\n",
    "\n",
    "first tips (and most import one) is to change 'id'-type/ label data into categorical type. Which, basically everything except 'timestamp', 'longitude', 'latitude'\n",
    "\n",
    "Note: we need to use some common sense to decide which featuers should be 'category' type not just based on the their default data type. e.g. timestamp has object type, but it should not be 'category' type (duh). While, 'app_id', 'device_id', 'label_id' are 'int64' type by default, but they are actually 'category' type.\n",
    "\n",
    "Here is how we do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show starter: lighter and faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   event_id     130821 non-null  category\n",
      " 1   timestamp    130821 non-null  object  \n",
      " 2   longitude    130821 non-null  float64 \n",
      " 3   latitude     130821 non-null  float64 \n",
      " 4   app_id       130821 non-null  int64   \n",
      " 5   device_id    130821 non-null  int64   \n",
      " 6   label_id     130821 non-null  int64   \n",
      " 7   gender       130821 non-null  object  \n",
      " 8   brand_parse  130821 non-null  object  \n",
      " 9   model_parse  130821 non-null  object  \n",
      "dtypes: category(1), float64(2), int64(3), object(4)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df_original.copy()\n",
    "df_tmp.event_id = df_tmp.event_id.astype('category')\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showcase 1: lighter\n",
    "let's try to make 'gender' into 'category' type.\n",
    "we have saved aroud 10% of the memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   event_id     130821 non-null  int64   \n",
      " 1   timestamp    130821 non-null  object  \n",
      " 2   longitude    130821 non-null  float64 \n",
      " 3   latitude     130821 non-null  float64 \n",
      " 4   app_id       130821 non-null  int64   \n",
      " 5   device_id    130821 non-null  int64   \n",
      " 6   label_id     130821 non-null  int64   \n",
      " 7   gender       130821 non-null  category\n",
      " 8   brand_parse  130821 non-null  object  \n",
      " 9   model_parse  130821 non-null  object  \n",
      "dtypes: category(1), float64(2), int64(4), object(3)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# encode the 'gender'\n",
    "df_tmp = df_original.copy()\n",
    "df_tmp.gender = df_tmp.gender.astype('category')\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show case 2: faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ms Â± 268 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n",
      "4.7 ms Â± 117 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df_original.groupby('gender').latitude.mean()\n",
    "\n",
    "df_tmp = df_original.copy()\n",
    "df_tmp.gender = df_tmp.gender.astype('category')\n",
    "\n",
    "%timeit df_tmp.groupby('gender').latitude.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4 ms Â± 727 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n",
      "18.9 ms Â± 383 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# even for device_id, it is still faster\n",
    "%timeit df_original.groupby('device_id').latitude.mean()\n",
    "\n",
    "df_tmp = df_original.copy()\n",
    "df_tmp.gender = df_tmp.gender.astype('category')\n",
    "\n",
    "%timeit df_tmp.groupby('device_id').latitude.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   event_id     130821 non-null  category\n",
      " 1   timestamp    130821 non-null  object  \n",
      " 2   longitude    130821 non-null  float64 \n",
      " 3   latitude     130821 non-null  float64 \n",
      " 4   app_id       130821 non-null  int64   \n",
      " 5   device_id    130821 non-null  int64   \n",
      " 6   label_id     130821 non-null  int64   \n",
      " 7   gender       130821 non-null  object  \n",
      " 8   brand_parse  130821 non-null  object  \n",
      " 9   model_parse  130821 non-null  object  \n",
      "dtypes: category(1), float64(2), int64(3), object(4)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# encode 'event_id'\n",
    "df_tmp = df_original.copy()\n",
    "df_tmp.event_id = df_tmp.event_id.astype('category')\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   event_id     130821 non-null  int64   \n",
      " 1   timestamp    130821 non-null  object  \n",
      " 2   longitude    130821 non-null  float64 \n",
      " 3   latitude     130821 non-null  float64 \n",
      " 4   app_id       130821 non-null  category\n",
      " 5   device_id    130821 non-null  category\n",
      " 6   label_id     130821 non-null  category\n",
      " 7   gender       130821 non-null  category\n",
      " 8   brand_parse  130821 non-null  category\n",
      " 9   model_parse  130821 non-null  category\n",
      "dtypes: category(6), float64(2), int64(1), object(1)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# encode several\n",
    "df_tmp = df_original.copy()\n",
    "col_cate_list =  [\n",
    "#     'event_id', \n",
    "    'device_id', \n",
    "    'app_id', 'label_id', 'gender', 'brand_parse', 'model_parse'\n",
    "                 ]\n",
    "df_tmp.loc[:,col_cate_list] = df_tmp.loc[:,col_cate_list].astype('category')\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have guessed it right, the number of unique event_id is large, while gender only has two unique values (M and F), would that the reason?\n",
    "\n",
    "Let's continue and make those features with few unique values into 'category' type. Namely, 'app_id', 'label_id', 'gender', 'brand_parse', 'model_parse'.\n",
    "\n",
    "Ahah, this time, we have saved near 40% of the memory usage. That's a lot. \n",
    "\n",
    "- But why sometimes using 'category' data type can save us memory usage, but sometimes not? What is going on here?\n",
    "\n",
    "- Also is that possible to pick other combinations and even save more memory usage? (remember I made a heavy 18G data loose its weight to 5G, saving more than 70% of the memory. How I did that?)\n",
    "\n",
    "- Is there any other way to do that?\n",
    "\n",
    "Ok, hold your horses, let's address the following question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explain how 'category' dtypes works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's time to talk about data type.\n",
    "\n",
    "note: the inherent python data types are... But since Numpy is almost like the default library of python, also pandas uses Numpy as backend. In this post, the data type is Numpy data type, which includes.\n",
    "\n",
    "table: https://pbpython.com/pandas_dtypes.html (add bytes taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- But why sometimes using 'category' data type can save us memory usage, but sometimes not? What is going on here?\n",
    "First of all, 'category' is a pandas data type. In pandas documentation, \n",
    "\n",
    "'Categoricals are a pandas data type corresponding to categorical variables in statistics. A categorical variable takes on a limited, and usually fixed, number of possible values (categories; levels in R). Examples are gender, social class, blood type, country affiliation, observation time or rating via Likert scales.'\n",
    "\n",
    "But the definition is not important, what we care the most is why using 'category' data type can save space. \n",
    "\n",
    "The mechanism behind is the idea of 'hash table'. before we talk about hash table, here is a brief reiview of datatype table and memory consumed in Bytes...\n",
    "\n",
    "\n",
    "let's take 'gender' feature for instance. there are 130821 iterms (rows), if each iterm is a object data type and each object data take up 8 Bytes of memory. Then in total the memory cosumed would be 130821 * 8 = 1,046,568 Bytes, this is same with the value using 'nbytes' function. Similarly, for 'brand_parse' and 'app_id', they both take up 130821 * 8 = 1,046,568. (note: each int64 also consume 8 Bytes)\n",
    "\n",
    "Next, if we change the data type from 'object' to 'category', the calculation is a little bit more complicated. I use a formula to calculate that: \n",
    "bytes_hashed * num_of_row + (0 + bytes_object) * n_unique, \n",
    "where bytes_hashed = hash_func(n_unique)\n",
    "- bytes_hashed is the int type that can cover up the n_unique values. e.g. there 2 unique values in gender, an int8 dtype can cover it up. an int8 dtype takes up 1 bytes. So, bytes_hashed = 1. another example, there 2660 unique values in gender, an int16 dtype can cover it up. an int16 dtype takes up 2 bytes. So, bytes_hashed = 2\n",
    "- the 8 byptes is the original class name in the hash table. Since the original class name in the hash table is a object type, which take up 8 bytes. (that's the reason why the number of classes are close to the row, using category type would even cosume more memory space)\n",
    "\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.ndarray.nbytes.html#numpy.ndarray.nbytes, pandas.Series.nbytes return 'Total bytes consumed by the elements of the array'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   gender       130821 non-null  object\n",
      " 1   brand_parse  130821 non-null  object\n",
      " 2   app_id       130821 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_original[['gender', 'brand_parse', 'app_id']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046568\n",
      "1046568\n"
     ]
    }
   ],
   "source": [
    "# gender original (object)\n",
    "print(8 * 130821)\n",
    "print(df_original.gender.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130837\n",
      "130837\n"
     ]
    }
   ],
   "source": [
    "# gender encode (category)\n",
    "print(1*130821 + (0+8)*2)\n",
    "print(df_original.gender.astype('category').nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "131429\n",
      "131429\n",
      "\n",
      "2660\n",
      "282922\n",
      "282922\n"
     ]
    }
   ],
   "source": [
    "# more example\n",
    "\n",
    "# brand_parse\n",
    "print(df_original.brand_parse.nunique())\n",
    "print(1* 130821+ (0 + 8) *76)\n",
    "print(df_original.brand_parse.astype('category').nbytes)\n",
    "print()\n",
    "\n",
    "# app_id\n",
    "print(df_original.app_id.nunique())\n",
    "print(2* 130821+ (0 + 8) * 2660)\n",
    "print(df_original.app_id.astype('category').nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what about ('actual') memory_usage\n",
    "the actual memory_usage can be a bit different from nbytes. we can check the memory with .memory_usage(). The formula to calculate memory_usage can be very tedious, which is out of the scope of this post. But if you are intrested go check pandas' document. https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    "\n",
    "Generally speaking, using nbytes to estimate memory_usage would be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "208\n",
      "2688\n",
      "82048\n"
     ]
    }
   ],
   "source": [
    "# what about memory_usage\n",
    "print(df_original.gender.memory_usage()- df_original.gender.nbytes)\n",
    "print(df_original.brand_parse.memory_usage()- df_original.brand_parse.nbytes)\n",
    "print(df_original.brand_parse.memory_usage()- df_original.app_id.nbytes)\n",
    "\n",
    "# print(df_original.gender.memory_usage(index=False)- df_original.gender.nbytes)\n",
    "# print(df_original.brand_parse.memory_usage(index=False)- df_original.brand_parse.nbytes)\n",
    "# print(df_original.brand_parse.memory_usage(index=False)- df_original.app_id.nbytes)\n",
    "\n",
    "print(df_original.gender.astype('category').memory_usage() - df_original.gender.astype('category').nbytes)\n",
    "print(df_original.brand_parse.astype('category').memory_usage() - df_original.brand_parse.astype('category').nbytes)\n",
    "print(df_original.app_id.astype('category').memory_usage() - df_original.app_id.astype('category').nbytes)\n",
    "\n",
    "# print(df_original.gender.astype('category').memory_usage(index=False) - df_original.gender.astype('category').nbytes)\n",
    "# print(df_original.brand_parse.astype('category').memory_usage(index=False) - df_original.brand_parse.astype('category').nbytes)\n",
    "# print(df_original.app_id.astype('category').memory_usage(index=False) - df_original.app_id.astype('category').nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also is that possible to pick other combinations and even save more memory usage? (remember I made a heavy 18G data loose its weight to 5G, saving more than 70% of the memory. How I did that?)\n",
    "\n",
    "- Is there any other way to do that? why use 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_id    :  107900 (0.82)\n",
      "timestamp   :   97356 (0.74)\n",
      "longitude   :    2071 (0.02)\n",
      "latitude    :    2057 (0.02)\n",
      "app_id      :    2660 (0.02)\n",
      "device_id   :   13986 (0.11)\n",
      "label_id    :     353 (0.00)\n",
      "gender      :       2 (0.00)\n",
      "brand_parse :      76 (0.00)\n",
      "model_parse :     761 (0.01)\n"
     ]
    }
   ],
   "source": [
    "for col in df_original.columns:\n",
    "    print('{:11}'.format(col), ': ', '{:6} ({:.2f})'.format(df_original[col].nunique(), df_original[col].nunique()/len(df_original)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046568\n",
      "130837\n",
      "130821\n"
     ]
    }
   ],
   "source": [
    "# other options \n",
    "print(df_original.gender.nbytes)\n",
    "print(df_original.gender.astype('category').nbytes)\n",
    "print(df_original.gender.astype('bool').nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         True\n",
       "1         True\n",
       "2         True\n",
       "3         True\n",
       "4         True\n",
       "          ... \n",
       "130816    True\n",
       "130817    True\n",
       "130818    True\n",
       "130819    True\n",
       "130820    True\n",
       "Name: brand_parse, Length: 130821, dtype: bool"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is wrong but we got no warning\n",
    "df_tmp = df_original.copy()\n",
    "df_tmp.brand_parse = df_tmp.brand_parse.astype('bool')\n",
    "df_tmp.brand_parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why category dtypes matters to machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a machine learning package cannot directly handle categorical variables, there are two conventions to encode categorical data. Label encoding and one hot encoding\n",
    "\n",
    "(Note: theoretically, a machine learning model, like random forest, has no problem to take categorical data. But the random forest model in Sklearn cannot handle categorical data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoder\n",
    "\n",
    "Take brand_parse for example, we can use label encoder, I.e. Huawei, xiaomi... to  0, 1, 2, 3...(Int type)\n",
    "\n",
    "The problem of this way of encoding is that the machine learning model might miss interpret the meaning of the encoded labels as ordinal (meaning with orders) while the original categorical data is nominal, I.e. it doesnâ€™t make much sense to say huawei is less than Xiaomi, xiaomi is less Meiji, etc.  thus the tree algorithm could improperly split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_parse</th>\n",
       "      <th>brand_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meizu</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130816</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130817</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130818</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130819</th>\n",
       "      <td>vivo</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130820</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130821 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand_parse  brand_encode\n",
       "0             OPPO            49\n",
       "1            Meizu            39\n",
       "2           Huawei            28\n",
       "3             OPPO            49\n",
       "4           Huawei            28\n",
       "...            ...           ...\n",
       "130816        OPPO            49\n",
       "130817      Huawei            28\n",
       "130818      Huawei            28\n",
       "130819        vivo            74\n",
       "130820      Huawei            28\n",
       "\n",
       "[130821 rows x 2 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "brand_parse_label_encode = LabelEncoder().fit_transform(df_original.brand_parse)\n",
    "pd.concat([df_original.brand_parse, pd.DataFrame({'brand_encode': brand_parse_label_encode})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   brand_parse   130821 non-null  object\n",
      " 1   brand_encode  130821 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.concat([df_original.brand_parse, pd.DataFrame({'brand_encode': brand_parse_label_encode})], axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding\n",
    "\n",
    "Conceptually, by using one hot encoding it will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_parse</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meizu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130816</th>\n",
       "      <td>OPPO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130817</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130818</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130819</th>\n",
       "      <td>vivo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130820</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130821 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand_parse  0  1  2  3  4  5  6  7  8  ...  66  67  68  69  70  71  \\\n",
       "0             OPPO  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "1            Meizu  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "2           Huawei  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "3             OPPO  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "4           Huawei  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "...            ... .. .. .. .. .. .. .. .. ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "130816        OPPO  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "130817      Huawei  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "130818      Huawei  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "130819        vivo  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "130820      Huawei  0  0  0  0  0  0  0  0  0  ...   0   0   0   0   0   0   \n",
       "\n",
       "        72  73  74  75  \n",
       "0        0   0   0   0  \n",
       "1        0   0   0   0  \n",
       "2        0   0   0   0  \n",
       "3        0   0   0   0  \n",
       "4        0   0   0   0  \n",
       "...     ..  ..  ..  ..  \n",
       "130816   0   0   0   0  \n",
       "130817   0   0   0   0  \n",
       "130818   0   0   0   0  \n",
       "130819   0   0   1   0  \n",
       "130820   0   0   0   0  \n",
       "\n",
       "[130821 rows x 77 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "brand_parse_one_hot_encode = ohe.fit_transform(X=df_original.brand_parse.values.reshape(-1, 1))\n",
    "pd.concat([df_original.brand_parse, pd.DataFrame(brand_parse_one_hot_encode).astype('int8')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130821 entries, 0 to 130820\n",
      "Data columns (total 77 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   brand_parse  130821 non-null  object\n",
      " 1   0            130821 non-null  int8  \n",
      " 2   1            130821 non-null  int8  \n",
      " 3   2            130821 non-null  int8  \n",
      " 4   3            130821 non-null  int8  \n",
      " 5   4            130821 non-null  int8  \n",
      " 6   5            130821 non-null  int8  \n",
      " 7   6            130821 non-null  int8  \n",
      " 8   7            130821 non-null  int8  \n",
      " 9   8            130821 non-null  int8  \n",
      " 10  9            130821 non-null  int8  \n",
      " 11  10           130821 non-null  int8  \n",
      " 12  11           130821 non-null  int8  \n",
      " 13  12           130821 non-null  int8  \n",
      " 14  13           130821 non-null  int8  \n",
      " 15  14           130821 non-null  int8  \n",
      " 16  15           130821 non-null  int8  \n",
      " 17  16           130821 non-null  int8  \n",
      " 18  17           130821 non-null  int8  \n",
      " 19  18           130821 non-null  int8  \n",
      " 20  19           130821 non-null  int8  \n",
      " 21  20           130821 non-null  int8  \n",
      " 22  21           130821 non-null  int8  \n",
      " 23  22           130821 non-null  int8  \n",
      " 24  23           130821 non-null  int8  \n",
      " 25  24           130821 non-null  int8  \n",
      " 26  25           130821 non-null  int8  \n",
      " 27  26           130821 non-null  int8  \n",
      " 28  27           130821 non-null  int8  \n",
      " 29  28           130821 non-null  int8  \n",
      " 30  29           130821 non-null  int8  \n",
      " 31  30           130821 non-null  int8  \n",
      " 32  31           130821 non-null  int8  \n",
      " 33  32           130821 non-null  int8  \n",
      " 34  33           130821 non-null  int8  \n",
      " 35  34           130821 non-null  int8  \n",
      " 36  35           130821 non-null  int8  \n",
      " 37  36           130821 non-null  int8  \n",
      " 38  37           130821 non-null  int8  \n",
      " 39  38           130821 non-null  int8  \n",
      " 40  39           130821 non-null  int8  \n",
      " 41  40           130821 non-null  int8  \n",
      " 42  41           130821 non-null  int8  \n",
      " 43  42           130821 non-null  int8  \n",
      " 44  43           130821 non-null  int8  \n",
      " 45  44           130821 non-null  int8  \n",
      " 46  45           130821 non-null  int8  \n",
      " 47  46           130821 non-null  int8  \n",
      " 48  47           130821 non-null  int8  \n",
      " 49  48           130821 non-null  int8  \n",
      " 50  49           130821 non-null  int8  \n",
      " 51  50           130821 non-null  int8  \n",
      " 52  51           130821 non-null  int8  \n",
      " 53  52           130821 non-null  int8  \n",
      " 54  53           130821 non-null  int8  \n",
      " 55  54           130821 non-null  int8  \n",
      " 56  55           130821 non-null  int8  \n",
      " 57  56           130821 non-null  int8  \n",
      " 58  57           130821 non-null  int8  \n",
      " 59  58           130821 non-null  int8  \n",
      " 60  59           130821 non-null  int8  \n",
      " 61  60           130821 non-null  int8  \n",
      " 62  61           130821 non-null  int8  \n",
      " 63  62           130821 non-null  int8  \n",
      " 64  63           130821 non-null  int8  \n",
      " 65  64           130821 non-null  int8  \n",
      " 66  65           130821 non-null  int8  \n",
      " 67  66           130821 non-null  int8  \n",
      " 68  67           130821 non-null  int8  \n",
      " 69  68           130821 non-null  int8  \n",
      " 70  69           130821 non-null  int8  \n",
      " 71  70           130821 non-null  int8  \n",
      " 72  71           130821 non-null  int8  \n",
      " 73  72           130821 non-null  int8  \n",
      " 74  73           130821 non-null  int8  \n",
      " 75  74           130821 non-null  int8  \n",
      " 76  75           130821 non-null  int8  \n",
      "dtypes: int8(76), object(1)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.concat([df_original.brand_parse, pd.DataFrame(brand_parse_one_hot_encode).astype('int8')], axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first issue is memory usage. You should not use dense matrix otherwise you are very likely to experience memory blow up. E.g. after one hot encode brand_parse will turn into 76 columns, even use the most efficient datatype (int8 or boolean), it still take a lot of memory; imagine if there more than 76 sub-classes.\n",
    "\n",
    "There are \n",
    "\n",
    "**Potential solution 1**: use sparse matrix\n",
    "\n",
    "- advantage: save space\n",
    "- disadvantage: hard for human being to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79539168\n",
      "1046568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<130821x76 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 130821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sparse\n",
    "brand_parse_one_hot_encode = OneHotEncoder(sparse=True).fit_transform(X=df_original.brand_parse.values.reshape(-1, 1))\n",
    "\n",
    "print(OneHotEncoder(sparse=False).fit_transform(X=df_original.brand_parse.values.reshape(-1, 1)).data.nbytes)\n",
    "print(brand_parse_one_hot_encode.data.nbytes)\n",
    "brand_parse_one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 49)\t1.0\n",
      "  (1, 39)\t1.0\n",
      "  (2, 28)\t1.0\n",
      "  (3, 49)\t1.0\n",
      "  (4, 28)\t1.0\n",
      "  (5, 59)\t1.0\n",
      "  (6, 28)\t1.0\n",
      "  (7, 67)\t1.0\n",
      "  (8, 35)\t1.0\n",
      "  (9, 72)\t1.0\n",
      "  (10, 28)\t1.0\n",
      "  (11, 28)\t1.0\n",
      "  (12, 59)\t1.0\n",
      "  (13, 28)\t1.0\n",
      "  (14, 67)\t1.0\n",
      "  (15, 67)\t1.0\n",
      "  (16, 28)\t1.0\n",
      "  (17, 67)\t1.0\n",
      "  (18, 49)\t1.0\n",
      "  (19, 39)\t1.0\n",
      "  (20, 35)\t1.0\n",
      "  (21, 35)\t1.0\n",
      "  (22, 74)\t1.0\n",
      "  (23, 39)\t1.0\n",
      "  (24, 59)\t1.0\n",
      "  :\t:\n",
      "  (130796, 74)\t1.0\n",
      "  (130797, 28)\t1.0\n",
      "  (130798, 67)\t1.0\n",
      "  (130799, 59)\t1.0\n",
      "  (130800, 74)\t1.0\n",
      "  (130801, 32)\t1.0\n",
      "  (130802, 28)\t1.0\n",
      "  (130803, 28)\t1.0\n",
      "  (130804, 28)\t1.0\n",
      "  (130805, 39)\t1.0\n",
      "  (130806, 28)\t1.0\n",
      "  (130807, 28)\t1.0\n",
      "  (130808, 28)\t1.0\n",
      "  (130809, 70)\t1.0\n",
      "  (130810, 28)\t1.0\n",
      "  (130811, 13)\t1.0\n",
      "  (130812, 32)\t1.0\n",
      "  (130813, 62)\t1.0\n",
      "  (130814, 28)\t1.0\n",
      "  (130815, 28)\t1.0\n",
      "  (130816, 49)\t1.0\n",
      "  (130817, 28)\t1.0\n",
      "  (130818, 28)\t1.0\n",
      "  (130819, 74)\t1.0\n",
      "  (130820, 28)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# sparse matrix is hard to interpret\n",
    "print(brand_parse_one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentials solution 2: group or dispose sub-classes\n",
    "\n",
    "- advantage: save space,\n",
    "- disadvantage: hard to decide which sub-classes to group or dispose, risk losing information\n",
    "\n",
    "Additionally, there is a saying, tree algorithms do not favor one-hot-encoding data, since it is likely to grow sparse trees. (ref: [https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769](https://towardsdatascience.com/one-hot-encoding-is-making-your-tree-based-ensembles-worse-heres-why-d64b282b5769))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips: pickle is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97 s Â± 101 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_sample.to_csv('./df_example.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 ms Â± 1.43 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_sample.to_pickle('./df_example_pkl.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways from this article\n",
    "\n",
    "- How to use 'category'? astype('category')\n",
    "- Why you should use 'category'? Save memory (except the Gochas situation), speed up operation performance (most likely), and improve machine learning performance (no proof but there are good reasons).\n",
    "- When to use it? Almost always; at least give it a try. Even though sometime it might take more space, but in the long run, it speed up operation performance and can seamless integrate into machine learning models with categorical feature support.\n",
    "- But, 'category' is not the silver bullet. Trial-and-error and iteration is your friend.\n",
    "- Stop to_csv, start to_pickle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blog]",
   "language": "python",
   "name": "conda-env-blog-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
